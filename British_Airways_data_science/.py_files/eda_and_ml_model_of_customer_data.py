# -*- coding: utf-8 -*-
"""eda_and_ml-model_of-customer_data.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1KSEDRoIO9qwj8OOyx1gydXSCoxwP5rCt

## Exploratory Data Analysis (EDA) on Customer Bookings data for British Airways

We will explore the customer data first to get to know it better in depth.
"""

# imports necessary modules
import pandas as pd
import numpy as np
import os

import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.preprocessing import OneHotEncoder
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split

from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score
from sklearn.metrics import f1_score
from sklearn.metrics import precision_score
from sklearn.metrics import recall_score
from sklearn.inspection import permutation_importance

from yellowbrick.classifier import ConfusionMatrix
from sklearn.model_selection import GridSearchCV,  RepeatedStratifiedKFold

#read the csv
df = pd.read_csv("data/customer_booking.csv",  encoding="ISO-8859-1")

# first five rows
df.head()

# shape of the data
df.shape

# detailed statistics
df.describe()

# information on data
df.info()

"""### Sales Channel"""

# calculate the number of booking by using internet and phone
per_internet = df.sales_channel.value_counts().values[0]  / df.sales_channel.count() *100
per_mobile = df.sales_channel.value_counts().values[1]  / df.sales_channel.count() *100

print(f"Number of bookings done through internet: {per_internet} %")
print(f"Number of bookings done through phone call: {per_mobile} %")

"""### Trip Type"""

# trip types in percentage
per_round = df.trip_type.value_counts().values[0]/ df.trip_type.count() *100
per_oneway = df.trip_type.value_counts().values[1]/ df.trip_type.count() *100
per_circle = df.trip_type.value_counts().values[2]/ df.trip_type.count() *100

print(f"Percentage of round trips: {per_round} %")
print(f"Percentage of One way trips: {per_oneway} %")
print(f"Percentage of circle trips: {per_circle} %")

"""### Purchase Lead"""

# image on purchase lead
plt.figure(figsize=(10,3))
sns.histplot(data=df, x="purchase_lead", binwidth=15,kde=True)
plt.show()

"""There are few bookings that were done more than 2 years before the travel date and it seems very unlikely that book that in advance. However, it might also be because of the cancellation and rebooking in a period of 6 months for twice. Generally airline keep the tickets for rebooking within a year. But at this point we will consider them as outliers which will effect the results of predictive model in a huge way."""

# detecting outliers; more then 600 days
(df.purchase_lead >600).value_counts()

"""If we assume that no customer is booking in advance of more than 1 and half year we will remove all entries with purchase_lead more than 600 days."""

# purchase lead more than 600 days
df[df.purchase_lead > 600]

# data to have only purchase lead days less than 600 days
df = df[df.purchase_lead <600 ]

"""### Length Of Stay"""

# how many days stay
plt.figure(figsize=(10,3))
sns.histplot(data=df, x="length_of_stay", binwidth=15,kde=True)
plt.show()

"""Let's see how many entries do we have that exceeds length of stay more than 100 days."""

# count stay more than 100 days
(df.length_of_stay> 200).value_counts()

# detecting if the booking is complete where the length of stay is more than 500 days
df[df.length_of_stay> 500].booking_complete.value_counts()

"""We need to have more business knowledge to decide whether to remove these entries with more than 600 days of stay. There are could be many reasons for such bookings. But for now, we will just want to focus on bookings done for length of stay less than 500 days."""

# filtering the data to have only length of stay days less than 500 days
df = df[df.purchase_lead <500 ]

"""### Flight Day

We will map the flight day with a number of a week.
"""

mapping = {
    "Mon" : 1,
    "Tue" : 2,
    "Wed" : 3,
    "Thu" : 4,
    "Fri" : 5,
    "Sat" : 6,
    "Sun" : 7
}

df.flight_day = df.flight_day.map(mapping)

df.flight_day.value_counts()

"""**Note: Most of the customers want to travel on Monday and choose Saturday as least preffered day as flight day.**

### Booking Origin
"""

# country from where the booking happened
plt.figure(figsize=(10,3))
ax = df.booking_origin.value_counts()[:20].plot(kind="bar")
ax.set_xlabel("Countries")
ax.set_ylabel("Number of bookings")
plt.show()

"""**Australia** had maximum booking applications."""

# Most booking complete
plt.figure(figsize=(10,3))
ax = df[df.booking_complete ==1].booking_origin.value_counts()[:20].plot(kind="bar")
ax.set_xlabel("Countries")
ax.set_ylabel("Number of complete bookings")
plt.show()

"""**Malaysia** had their booking complete.

### Booking complete
"""

# successful booking percentage
successful_booking_per = df.booking_complete.value_counts().values[0] / len(df) * 100

# unsuccessful booking percentage
unsuccessful_booking_per = 100-successful_booking_per

print(f"Out of 50000 booking entries only {round(unsuccessful_booking_per,2)} % bookings were successfull or complete.")

"""## Export the dataset to csv


"""

df.to_csv("data/cleaned_and_filtered_customer_booking.csv")

"""### Predictive Model"""

# import data
df = pd.read_csv("data/cleaned_and_filtered_customer_booking.csv", index_col=0)

# setting index
df = df.reset_index(drop=True)

df

# one hot encoding to categorical data
df_final = df

# create instance of one hot encoder
encoder = OneHotEncoder(handle_unknown='ignore')

# one hot encode Sales Channel
encoder_df = pd.DataFrame(encoder.fit_transform(df[["sales_channel"]]).toarray())
encoder_df = encoder_df.rename(columns={0:'Internet', 1:'Mobile'})
df_final = df_final.join(encoder_df)

# one hot encode trip type
encoder_df = pd.DataFrame(encoder.fit_transform(df[["trip_type"]]).toarray())
encoder_df = encoder_df.rename(columns={0:'RoundTRip', 1:'OneWayTrip',2:'CircleTrip'})
df_final = df_final.join(encoder_df)

# drop categorical columns now
df_final.drop(['sales_channel', 'trip_type','booking_origin', 'route'], axis=1, inplace = True)

# store the label for supervised learning
label = df['booking_complete']

df_final = df_final.drop('booking_complete', axis=1)

df_final

"""### Normalizing Values"""

# create a standard scaler object
scaler = StandardScaler()

# fit and transform the data
scaled_df = scaler.fit_transform(df_final)

# create a dataframe of scled data
scaled_df = pd.DataFrame(scaled_df, columns = df_final.columns)

# add the labels back to the dataframe
scaled_df['label']  = label

scaled_df

# correlation matrix
corr = scaled_df.corr()

#plot the heatmap
plt.figure(figsize=(10,4))
sns.heatmap(corr)
plt.show()

# Handle NaN values in 'label' column before train-test split

# Calculate the mean of the 'label' column (excluding NaN values)
mean_label = scaled_df['label'].mean()

# remove rows with NaN values in 'label'
scaled_df.dropna(subset=['label'], inplace=True)

# train-test split
X = scaled_df.iloc[:,:-1]
y = scaled_df['label']

# Convert y to integers before splitting
#y = y.astype(int)

X_train, X_test, y_train, y_test = train_test_split(X.to_numpy(), y.to_numpy(), test_size=0.20, random_state=42)

# Create functions to fit and predict the values; whether customer would complete the booking or not
# Functions with metrics to evaluate the model prediction

def model_fit_predict(model, X, y, X_predict):
  """
  Will fit the model and predict the values

  Parameters
  ----------
  model: input model
  X: training input
  y: training output
  X_predict: testing input

  Returns
  -------
  model prediction
  """
  model.fit(X, y)
  return model.predict(X_predict)

def acc_score(y_true, y_pred):
  """
  Calculate the accuracy score

  Parameters
  ----------
  y_true: actual values
  y_pred: predicted values

  Returns
  -------
  accuracy score
  """
  return accuracy_score(y_true, y_pred)

def pre_score(y_true, y_pred):
  """
  Calculate the precision score

  Parameters
  ----------
  y_true: actual values
  y_pred: predicted values

  Returns
  -------
  precision score
  """
  return precision_score(y_true, y_pred)

def f_score(y_true, y_pred):
  """
  Calculate the f1 score

  Parameters
  ----------
  y_true: actual values
  y_pred: predicted values

  Returns
  -------
  f1 score
  """
  return f1_score(y_true, y_pred)

"""### Random Forset"""

# create an instance of the classifier and fit the training data
clf_rf = RandomForestClassifier(max_depth =50 , min_samples_split=5,random_state=0)

# check training accuracy
y_pred_train = model_fit_predict(clf_rf, X_train, y_train, X_train)
set(y_pred_train)

#f1 score for training data
f1 = round(f1_score(y_train, y_pred_train),2)

#accuracy score for training data
acc = round(accuracy_score(y_train, y_pred_train),2)

#precision score for training data
pre = round(precision_score(y_train, y_pred_train),2)

print(f"Accuracy, precision and f1-score for training data are {acc}, {pre} and {f1} respectively")

# confusion matrix
cm = ConfusionMatrix(clf_rf, classes=[0,1])
cm.fit(X_train, y_train)
cm.score(X_train, y_train)

# testing accuracy
#create an instance of the classifier and fit the training data
clf_rf = RandomForestClassifier(max_depth =50 , min_samples_split=5,random_state=0)

y_pred_test = model_fit_predict(clf_rf, X_train, y_train, X_test)

#f1 score for training data
f1 = round(f1_score(y_test, y_pred_test),2)

#accuracy score for training data
acc = round(accuracy_score(y_test, y_pred_test),2)

#precision score for training data
pre = round(precision_score(y_test, y_pred_test),2)

print(f"Accuracy, precision and f1-score for training data are {acc}, {pre} and {f1} respectively")

# confusion matrix
cm = ConfusionMatrix(clf_rf, classes=[0,1])
cm.fit(X_train, y_train)

cm.score(X_test, y_test)

# important features
plt.figure(figsize=(10,3))
sorted_idx = clf_rf.feature_importances_.argsort()
plt.barh(scaled_df.iloc[:,:-1].columns[sorted_idx], clf_rf.feature_importances_[sorted_idx])
plt.xlabel("Random Forest Feature Importance")
plt.savefig("feature_importance.png", dpi=300)
plt.show()

"""**Note:** One major problem behind getting low F1 score is imbalanced dataset. We have higher entries that are classified 0 than 1. We could reduce the number of entries that are classified 0 to be equal around the number of entries that are classified as 1.

### Balance Datasheet
"""

scaled_df.label.value_counts()

# create a dataframe having all labels 0 with 10000 samples
scaled_df_0 = scaled_df[scaled_df.label ==0].sample(n=7476)

# oncatenate the two dataframee, one havng all labels 0 and other having all labels as 1
scaled_df_new = pd.concat([scaled_df[scaled_df.label==1], scaled_df_0], ignore_index=True)

#shuffle the dataframe rows
scaled_df_new = scaled_df_new.sample(frac = 1).reset_index(drop=True)

scaled_df_new

scaled_df_new.label.value_counts()

# train test
X = scaled_df_new.iloc[:,:-1]
y = scaled_df_new['label']

X_train, X_test, y_train, y_test = train_test_split(X.to_numpy(), y.to_numpy(), test_size=0.20, random_state=42)

#create an instance of the classifier and fit the training data
clf_rf = RandomForestClassifier(n_estimators=50,max_depth =50 , min_samples_split=5,random_state=0)

y_pred_test = model_fit_predict(clf_rf, X_train, y_train, X_test)

#f1 score for training data
f1 = round(f1_score(y_test, y_pred_test),2)

#accuracy score for training data
acc = round(accuracy_score(y_test, y_pred_test),2)

#precision score for training data
pre = round(precision_score(y_test, y_pred_test),2)

recall = round(recall_score(y_test, y_pred_test),2)

specificity = round(recall_score(y_test, y_pred_test, pos_label=0),2)

print(f"Accuracy, precision, recall and f1-score for training data are {acc}, {pre}, {recall}, and {f1} respectively")

# confusion matrix
cm = ConfusionMatrix(clf_rf, classes=[0,1])
cm.fit(X_train, y_train)
cm.score(X_test, y_test)

# feature importances
plt.figure(figsize=(10,8))
sorted_idx = clf_rf.feature_importances_.argsort()
plt.barh(scaled_df.iloc[:,:-1].columns[sorted_idx], clf_rf.feature_importances_[sorted_idx])
plt.xlabel("Random Forest Feature Importance")
plt.savefig("feature_importance_scaled.png", dpi=300)
plt.show()

